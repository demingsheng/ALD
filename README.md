# Learning Survival Distributions with the Asymmetric Laplace Distribution (ICML 2025)

This repository contains the official implementation of our ICML 2025 paper:

**Learning Survival Distributions with the Asymmetric Laplace Distribution**  
ğŸ“„ [Paper on arXiv](https://arxiv.org/abs/2505.03712)

## ğŸ” Overview
We propose a parametric survival analysis framework based on the Asymmetric Laplace Distribution (ALD), which enables closed-form computation of key distributional summaries such as mean, median, mode, and quantiles. Our method learns individual-level ALD parameters (location, scale, and asymmetry) via maximum likelihood estimation, supporting both observed and censored data. Compared to traditional and neural baselinesâ€”including DeepSurv, DeepHit, and CQRNNâ€”our model achieves superior performance in terms of accuracy, calibration, and discrimination across 21 datasets and 9 evaluation metrics. This approach provides a robust and interpretable alternative for survival modeling in both synthetic and real-world applications.

## ğŸ—‚ï¸ Directory Structure

```
datasets/
â”œâ”€â”€ breast_msk_2018_clinical_data.tsv   
â”œâ”€â”€ gbsg_cancer_train_test.h5            
â”œâ”€â”€ gbsg.csv                             
â”œâ”€â”€ lgggbm_tcga_pub_clinical_data.tsv    
â”œâ”€â”€ metabric_IHC4_clinical_train_test.h5  
â”œâ”€â”€ support_train_test.h5                
â”œâ”€â”€ tmb_immuno_mskcc.tsv                 
â””â”€â”€ whas_train_test.h5                  # real-world data with real censoring datasets

figures/
â”œâ”€â”€ *.png                               # Figures and visualizations generated during analysis

res/
â”œâ”€â”€ *.json                              # Experiment results

./
â”œâ”€â”€ datasets.py                         # Functions for loading and preprocessing datasets
â”œâ”€â”€ hyperparams.py                      # Hyperparameters used in the experiments 
â”œâ”€â”€ models.py                           # Neural network architectures and custom losses in the experiments 
â”œâ”€â”€ script.py                           # Main script for running experiments
â”œâ”€â”€ utils.py                            # Utility functions for common operations

requirements.txt                        # Python dependencies
README.md                               # Project description and usage instructions
```

---

## **Requirements**
Install the required dependencies using the `requirements.txt` file:
```bash
pip install -r requirements.txt
```

---

## **Usage**

### **1. Data Preparation**
Place all datasets in the `datasets/` folder. Preprocessing functions are available in `datasets.py`.

### **2. Running Experiments**
Use `script.py` to train and evaluate models:
```bash
python script.py
```

### **3. Visualizations**
Figures and plots generated during analysis will be saved in the `figures/` folder.
